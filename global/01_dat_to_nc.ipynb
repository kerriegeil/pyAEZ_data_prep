{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: K Geil\n",
    "\n",
    "Date: 05/2023\n",
    "\n",
    "Description: convert gaez dat files (daily deviation data from pxv files) to netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for computing\n",
    "import numpy as np\n",
    "import xarray as xr # for reading/writing netcdf\n",
    "import dask.array as da\n",
    "import dask\n",
    "import pandas as pd # only used for date times\n",
    "\n",
    "# convenience things\n",
    "from time import time, sleep\n",
    "import os\n",
    "import glob # for system commands\n",
    "from natsort import natsorted # for alphabetical sorting\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# from dask.distributed import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contain worker logs in their own folder\n",
    "homedir = os.environ['HOME']\n",
    "daskpath=os.path.join(homedir, \"dask-worker-space-can-be-deleted\")\n",
    "\n",
    "try: \n",
    "    os.mkdir(daskpath) \n",
    "except OSError as error: \n",
    "    print(error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your notebook directory location\n",
    "repo_dir='/work/hpc/users/kerrie/UN_FAO/repos/py_AEZ_data_prep/'\n",
    "nb_link='https://github.com/kerriegeil/pyAEZ_data_prep/blob/main/global/01_dat_to_nc.ipynb'\n",
    "\n",
    "# your data directory location\n",
    "data_dir='/work/hpc/users/kerrie/UN_FAO/data/'\n",
    "\n",
    "# the ALOSmask file that has matching grid to your pxv/dat data\n",
    "# maskfile='/work/hpc/users/kerrie/UN_FAO/scripts/PXV_script/ALOSmask5m_fill.rst'\n",
    "maskfile=data_dir+'/orig/DataDownload03152023/ALOSmask5m_fill.rst'\n",
    "\n",
    "# linux path of project directory (to include in file metadata)\n",
    "source_dirs=['on HPC2 /gri/projects/rgmg/climate/UN_FAO/data_downloads/2023-03-15_DataDownload/',\n",
    "             'on Orion /work/hpc/users/kerrie/UN_FAO/data/orig/DataDownload03152023/']\n",
    "\n",
    "year=1980\n",
    "\n",
    "fillval=-9999. # value used for missing in the dat files\n",
    "\n",
    "# metadata for output data files\n",
    "timeattrs={'standard_name':'time','long_name':'time','axis':'T'}\n",
    "yattrs={'standard_name':'latitude','long_name':'latitude','units':'degrees_north','axis':'Y'}\n",
    "xattrs={'standard_name':'longitude','long_name':'longitude','units':'degrees_east','axis':'X'}\n",
    "\n",
    "time_encoding={'calendar':'standard','units':'days since 1900-01-01 00:00:00','_FillValue':None}\n",
    "y_encoding={'_FillValue':None}\n",
    "x_encoding={'_FillValue':None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dat files to convert\n",
    "filelist=natsorted(glob.glob(data_dir+'gaez_dat_files/global_'+str(year)+'/*'+str(year)+'*'))\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save varnames for later\n",
    "varnames=['Precip','Srad','Tmin-2m','Tmax-2m','Vapr','Wind-10m']\n",
    "\n",
    "# also we have this scale and units info from the file \"UnitScaleFactors.txt\"\n",
    "scale_factor=[1E-5,1000.,0.01,0.01,0.01,0.001]\n",
    "units=['mm/day','J/m2/day','degrees C','degrees C','hPa','m/s']\n",
    "long_names=['precipitation','surface short wave radiation','2m minimum air temperature','2m maximum air temperature','vapor pressure','10m wind speed']\n",
    "\n",
    "# which var to process (0-based index of filelist) e.i. v=0 processed Precip\n",
    "v=2\n",
    "\n",
    "print('Processing variable =',varnames[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=open(filelist[v]).read().splitlines() # get each line as a string and remove carriage returns\n",
    "ilatilon=temp[0::2] # grab the lines with the lat/lons (every other line)\n",
    "data=temp[1::2]  # grab the lines with the data (every other line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each string lat/lon as integer and put it in an numpy array\n",
    "ilat=np.array([int(i.split()[0]) for i in ilatilon]).astype('int16') \n",
    "ilon=np.array([int(i.split()[1]) for i in ilatilon]).astype('int16') \n",
    "\n",
    "# put data in a numpy array too, takes 30-60s\n",
    "data2D=np.loadtxt(data,dtype='int16')\n",
    "nt=data2D.shape[1]\n",
    "\n",
    "print('data dimensions:', data2D.shape[0],'rows (each row represents a different grid cell) by',nt,'cols (each col represents a day of the year)')\n",
    "\n",
    "print('data min max:',data2D.min(),data2D.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=data2D[407:408:]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=test[test<0]\n",
    "missing=np.where(missing==-9999,1,0)\n",
    "missing.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get grid info from mask file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=xr.open_dataset(maskfile,engine='rasterio').squeeze()['band_data'] \n",
    "mask=mask.drop('band')\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny,nx=mask.shape\n",
    "yvals=mask.y.data.astype('float32')\n",
    "xvals=mask.x.data.astype('float32')\n",
    "\n",
    "# create a time dimension\n",
    "# doys=(np.arange(365)+1).astype('int32')\n",
    "time=pd.date_range(str(year)+'-01-01',str(year)+'-12-31',freq='D')\n",
    "\n",
    "# sometimes leap day is deleted out of the dataset, if so fix up time to match\n",
    "if len(time) != nt:\n",
    "    time=time[~(time==str(year)+'-02-29')]\n",
    "\n",
    "\n",
    "print('global data dimensions:',ny,'latitudes by',nx,'longitudes by',nt,'days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have the metadata needed (lat, lon, time info) to create an xarray data array to store global data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a compute cluster with dask distributed \n",
    "\n",
    "if you started jupyter notebook session with many nodes/cores, use LocalCluster below\n",
    "\n",
    "if you started jupyter notebook session with few cores, use SLURMCluster below\n",
    "\n",
    "\n",
    "- setting 1 worker to a full node of cores, then scaling up is the way to go\n",
    "\n",
    "- the default settings with less cores/threads per worker and more workers takes much longer to compute\n",
    "\n",
    "- for SLURMCluster we have to wait until the workers connect. You can log into orion and squeue -u username to see if you workers are stuck in pending due to lack of priority or nodes being down. DONT BUILD THE TASKLIST OR EXECUTE THE COMPUTATION UNTIL YOU SEE ALL WORKERS UP AND RUNNING (output from client under cluster info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LocalCluster\n",
    "# from dask.distributed import Client,LocalCluster\n",
    "# cluster=LocalCluster(n_workers=1,\n",
    "#                     threads_per_worker=20)\n",
    "\n",
    "\n",
    "# for SLURMCluster\n",
    "# when there's plenty of idle nodes choose cores=20, mem=180GB, then scale to 5\n",
    "# when there's no idle nodes choose cores=10, mem=90GB, then scale to 10\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(\n",
    "    cores=10, # actual cores (not logical) can't be more cores than are available on a single node (20 for Orion)\n",
    "    processes=1, # choose 1 process, then scale to more with cluster.scale below\n",
    "    memory=\"90GB\", # cores x mem/core\n",
    "    queue=\"400p48h\", #\"400p48h\", # for Orion MSU jobs (not NOAA)\n",
    "    local_directory='$TMPDIR', # should be the same for everyone\n",
    "    walltime=\"00:05:00\", # set this as short as possible or you'll have to go in and kill your workers\n",
    "    log_directory=daskpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LocalCluster\n",
    "# client=Client(cluster)\n",
    "# cluster.scale(4)  # adjust this to scale for however many cores are available in your notebook session\n",
    "# sleep(2)\n",
    "# client\n",
    "\n",
    "# for SLURMCluster\n",
    "client=Client(cluster)\n",
    "cluster.scale(jobs=10) # requesting jobs x the resources defined in cluster\n",
    "sleep(45) # SLURM takes a comparitively long time to fully connect to the workers, so wait (sometimes up to a full min is req)\n",
    "\n",
    "# don't start computing below until your workers show up here\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if workers didn't show up above keep executing the next block ('client') until they show up \n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to stop a localCluster or restart kernel\n",
    "# don't open multiple clusters\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dask delayed parallel computing to put data onto global grid\n",
    "\n",
    "loop thru each latitude to create a chunk of the global data array, where grid cells without data are filled with nan\n",
    "\n",
    "inside the loop we issue calls to functions that do the heavier computing tasks\n",
    "\n",
    "we delay those functions to create a dask task graph on length ny=2160 and then set off all the tasks to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a chunk of data for grids where data is present\n",
    "\n",
    "@dask.delayed\n",
    "def build_full_lat(ixs,data,y,x,t,fv,sf):\n",
    "#     arr=xr.DataArray(dims=['y','x','doy'],coords={'y':('y',y),'x':('x',x),'doy':('doy',t)}).astype('float16')\n",
    "    arr=xr.DataArray(np.nan,dims=['y','x','time'],coords={'y':('y',y),'x':('x',x),'time':('time',time)}).astype('float16')\n",
    "    for i,ix in enumerate(ixs):\n",
    "        arr[0:1,ix:ix+1,:]=data[i,:]\n",
    "    \n",
    "    arr=arr.where(arr!=fv)\n",
    "    arr=arr*sf # apply scale factor\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a chunk of data for grids where data is not present\n",
    "\n",
    "@dask.delayed\n",
    "def build_empty_lat(y,x,t):\n",
    "#     arr=xr.DataArray(dims=['y','x','doy'],coords={'y':('y',y),'x':('x',x),'doy':('doy',t)}).astype('float16')\n",
    "    arr=xr.DataArray(np.nan,dims=['y','x','time'],coords={'y':('y',y),'x':('x',x),'time':('time',time)}).astype('float16')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we write a normal not-delayed loop to call the delayed functions and collect all the delayed tasks into a list called tasklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasklist=[]\n",
    "\n",
    "# parellilze by latitude (latitude loop)\n",
    "for iy in range(ny):\n",
    "    indices=np.where(ilat==iy+1)[0] # find which data rows apply to this latitude\n",
    "    if np.any(indices):\n",
    "#         result=build_full_lat((ilon[indices]-1),data2D[indices,:],yvals[iy:iy+1],xvals,doys) # lazy call to func returns a task\n",
    "        result=build_full_lat((ilon[indices]-1),data2D[indices,:],yvals[iy:iy+1],xvals,time,fillval,scale_factor[v]) # lazy call to func returns a task\n",
    "        tasklist.append(result) # collect list of compute tasks\n",
    "    else:\n",
    "#         result=build_empty_lat(yvals[iy:iy+1],xvals,doys)\n",
    "        result=build_empty_lat(yvals[iy:iy+1],xvals,time)\n",
    "        tasklist.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask.compute starts the parallel computing and pulls all the results down from workers into a list of arrays\n",
    "\n",
    "note: the use of *tasklist means output will be a list of len ny=2160 of arrays, without * the output will be len 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=dask.compute(*tasklist)\n",
    "output[0] # look at 1 array in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now concat all the arrays into a single large array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigarr=xr.concat(output,dim='y')\n",
    "# bigarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write netcdf file\n",
    "\n",
    "first add appropriate metadata, then write compressed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable/coordinate metadata\n",
    "varattrs={'standard_name':varnames[v],'long_name':long_names[v],'units':units[v]}\n",
    "\n",
    "bigarr.name=varnames[v]\n",
    "bigarr.attrs=varattrs\n",
    "bigarr['y'].attrs=yattrs\n",
    "bigarr['x'].attrs=xattrs\n",
    "bigarr['time'].attrs=timeattrs\n",
    "\n",
    "ds=bigarr.to_dataset()\n",
    "ds=ds.assign_attrs({'source_data':source_dirs,\n",
    "                    'source_code':nb_link})\n",
    "\n",
    "print('bigarr is',bigarr.nbytes*1E-6,'MB')\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a look at part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigarr.sel(y=slice(50,23),x=slice(-90,-65),time='1980-06-01').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_encoding = {'zlib':True,'dtype':'float32'}\n",
    "\n",
    "# writing with compression will take a few minutes\n",
    "# if we want the file even smaller we could encode scale and offset\n",
    "ds.to_netcdf(data_dir+'gaez_nc_files/'+varnames[v]+'_DailyDev_'+str(year)+'_5m.nc',\n",
    "            encoding={'y':y_encoding,\n",
    "                      'x':x_encoding,\n",
    "                      'time':time_encoding,\n",
    "                      varnames[v]:var_encoding})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=xr.open_dataset(data_dir+'gaez_nc_files/'+varnames[v]+'_DailyDev_'+str(year)+'_5m.nc')\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var[varnames[v]].sel(y=slice(50,23),x=slice(-90,-65),time='1980-06-01').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr-rio-dask",
   "language": "python",
   "name": "xr-rio-dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
