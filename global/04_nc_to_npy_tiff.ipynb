{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Author: K Geil\n",
    "Date: 6/2023\n",
    "Description: save netcdfs as npy for faster loading in pyaez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # for system ls\n",
    "from natsort import natsorted # for alphabetical sorting\n",
    "\n",
    "import xarray as xr # for reading netcdf\n",
    "# import numpy as np\n",
    "import dask.array as da\n",
    "import dask\n",
    "import rioxarray as rio # for writing tif\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the same for everyone on HPC Orion\n",
    "\n",
    "data_nc = '/work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/'\n",
    "data_npy = '/work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/'\n",
    "data_tif = '/work/hpc/datasets/un_fao/pyaez/global_1980/daily/tif/'\n",
    "data_static = '/work/hpc/datasets/un_fao/pyaez/static/netcdf/'\n",
    "\n",
    "varnames = ['Precip','Rhum','Srad','Tmax-2m','Tmin-2m','Wind-2m']\n",
    "varnames365 = ['Precip365','Rhum365','Srad365','Tmax-2m365','Tmin-2m365','Wind-2m365']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netcdf to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.60 GiB </td>\n",
       "                        <td> 1.33 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1800, 4320, 366) </td>\n",
       "                        <td> (450, 2160, 366) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 4 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"127\" height=\"199\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"39\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"60\" x2=\"39\" y2=\"89\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"39\" y2=\"149\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"127\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"142\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"149\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 39.411764705882355,29.411764705882355 39.411764705882355,149.41176470588235 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"47\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"55\" y2=\"7\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"62\" y2=\"14\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"69\" y2=\"22\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"77\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"39\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"47\" y1=\"0\" x2=\"77\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 47.659013927290275,0.0 77.07077863317264,29.411764705882355 39.411764705882355,29.411764705882355\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"77\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"39\" y1=\"89\" x2=\"77\" y2=\"89\" />\n",
       "  <line x1=\"39\" y1=\"149\" x2=\"77\" y2=\"149\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"149\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"77\" y1=\"29\" x2=\"77\" y2=\"149\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"39.411764705882355,29.411764705882355 77.07077863317264,29.411764705882355 77.07077863317264,149.41176470588235 39.411764705882355,149.41176470588235\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"58.241272\" y=\"169.411765\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >366</text>\n",
       "  <text x=\"97.070779\" y=\"89.411765\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,97.070779,89.411765)\">4320</text>\n",
       "  <text x=\"14.705882\" y=\"154.705882\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,14.705882,154.705882)\">1800</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<transpose, shape=(1800, 4320, 366), dtype=float32, chunksize=(450, 2160, 366), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each 3D array has total size ~12.7GB\n",
    "# we need to chunk these arrays so that a chunk fits into memory (~9GB per single core)\n",
    "# any chunk size less than ~9GB should work, we'll use 8 chunks --> ~1.5GB per chunk\n",
    "\n",
    "chunks={'time':-1,'lat':450,'lon':2160} # 8 chunks\n",
    "\n",
    "# look at size of the chunks\n",
    "test=xr.open_dataset(data_nc+'Tmin-2m_daily_1980_5m.nc',chunks=chunks)['Tmin-2m'].sel(lat=slice(90,-60.)).transpose('lat','lon','time').data\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Precip_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Precip/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Rhum_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Rhum/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Srad_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Srad/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Tmax-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Tmax-2m/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Tmin-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Tmin-2m/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Wind-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Wind-2m/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/static/netcdf/mask_2268708_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/mask/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/static/netcdf/Elevation_2268708_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Elevation/0.npy\n"
     ]
    }
   ],
   "source": [
    "del test\n",
    "\n",
    "# do the nc to npy conversion for each variable\n",
    "# we are also subsetting the global array (to eliminate artarctica where all grids are nan)\n",
    "# expect about 1 min run time per variable\n",
    "\n",
    "for var in varnames:\n",
    "    # get nc file name\n",
    "    f = natsorted(glob.glob(data_nc+var+'*_5m.nc'))[0]\n",
    "        \n",
    "    if f:\n",
    "        # read netcdf data into a dask array of numpy array chunks\n",
    "        print('reading',f)\n",
    "        data = xr.open_dataset(f,chunks=chunks)[var].sel(lat=slice(90,-60.)).transpose('lat','lon','time').data        \n",
    "\n",
    "        # set up dir for writing npy\n",
    "        out_dir=data_npy+var+'/'\n",
    "        isExist = os.path.exists(out_dir)\n",
    "        if not isExist:\n",
    "            os.makedirs(out_dir)\n",
    "        # write npy data\n",
    "        print('writing to',out_dir+'0.npy')     \n",
    "        da.to_npy_stack(out_dir,data,axis=2)          \n",
    "    else:\n",
    "        print('no file',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Precip_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Precip365/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Rhum_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Rhum365/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Srad_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Srad365/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Tmax-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Tmax-2m365/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Tmin-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Tmin-2m365/0.npy\n",
      "reading /work/hpc/datasets/un_fao/pyaez/global_1980/daily/netcdf/Wind-2m_daily_1980_5m.nc\n",
      "writing to /work/hpc/datasets/un_fao/pyaez/global_1980/daily/npy/Wind-2m365/0.npy\n"
     ]
    }
   ],
   "source": [
    "# # to output files without the leap day run this\n",
    "\n",
    "# # do the nc to npy conversion for each variable\n",
    "# # we are also subsetting the global array (to eliminate artarctica where all grids are nan)\n",
    "# # we also drop the leap day to output 365 total days\n",
    "# # expect about 1 min run time per variable\n",
    "\n",
    "# with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "#     for var_in,var_out in zip(varnames,varnames365):\n",
    "#         # get nc file name\n",
    "#         f = natsorted(glob.glob(data_nc+var_in+'*_5m.nc'))[0]\n",
    "\n",
    "#         if f:\n",
    "#             # read netcdf data into a dask array of numpy array chunks\n",
    "#             print('reading',f)\n",
    "#             data = xr.open_dataset(f,chunks=chunks)[var_in].sel(lat=slice(90,-60.)).drop_sel(time='1980-02-29').transpose('lat','lon','time').data\n",
    "\n",
    "#             # set up dir for writing npy\n",
    "#             out_dir=data_npy+var_out+'/'\n",
    "#             isExist = os.path.exists(out_dir)\n",
    "#             if not isExist:\n",
    "#                 os.makedirs(out_dir)\n",
    "#             # write npy data\n",
    "#             print('writing to',out_dir+'0.npy')     \n",
    "#             da.to_npy_stack(out_dir,data,axis=2)          \n",
    "#         else:\n",
    "#             print('no file',f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netcdf mask and elevation to tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/hpc/datasets/un_fao/pyaez/static/netcdf/mask_2268708_5m.nc\n",
      "mask_2268708_5m.nc\n"
     ]
    }
   ],
   "source": [
    "# get file path and file name\n",
    "f = glob.glob(data_static+'mask_*_5m.nc')[0]\n",
    "filename=f.split('/')[-1]\n",
    "print(f)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /work/hpc/datasets/un_fao/pyaez/static/netcdf/mask_2268708_5m.nc\n",
      "writing /work/hpc/datasets/un_fao/pyaez/static/tif/mask_2268708_5m.tif\n"
     ]
    }
   ],
   "source": [
    "print('reading',f)\n",
    "\n",
    "# load mask from netcdf file\n",
    "data = xr.open_dataset(f)['mask'].sel(lat=slice(90,-60.))\n",
    "\n",
    "# write file\n",
    "outfile='/work/hpc/datasets/un_fao/pyaez/static/tif/'+filename[:-3]+'.tif'\n",
    "print('writing',outfile)\n",
    "data.rio.to_raster(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/hpc/datasets/un_fao/pyaez/static/netcdf/Elevation_2268708_5m.nc\n",
      "Elevation_2268708_5m.nc\n"
     ]
    }
   ],
   "source": [
    "# get file path and file name\n",
    "f = glob.glob(data_static+'Elevation_*_5m.nc')[0]\n",
    "filename=f.split('/')[-1]\n",
    "print(f)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /work/hpc/datasets/un_fao/pyaez/static/netcdf/Elevation_2268708_5m.nc\n",
      "writing /work/hpc/datasets/un_fao/pyaez/static/tif/Elevation_2268708_5m.tif\n"
     ]
    }
   ],
   "source": [
    "print('reading',f)\n",
    "\n",
    "# load mask from netcdf file\n",
    "data = xr.open_dataset(f)['Elevation'].sel(lat=slice(90,-60.))\n",
    "\n",
    "# write file\n",
    "outfile='/work/hpc/datasets/un_fao/pyaez/static/tif/'+filename[:-3]+'.tif'\n",
    "print('writing',outfile)\n",
    "data.rio.to_raster(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr-rio-dask",
   "language": "python",
   "name": "xr-rio-dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
